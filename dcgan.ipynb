{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haho6\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "images = []\n",
    "for i in range(70):\n",
    "    image = load_img('./DATA/'+str(i)+'.jpeg',target_size=(64,64))\n",
    "    image = img_to_array(image)\n",
    "    image.shape\n",
    "    image = image / 256\n",
    "    images.append(image)\n",
    "    images.append(image)\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size = [batch_size, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowUp(arr):\n",
    "    import cv2\n",
    "    frame = cv2.cvtColor(np.array(arr), cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 64,64,3])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "Z = tf.placeholder(tf.float32, [None, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(Z):\n",
    "    w1 = tf.Variable(tf.random_normal([100, 16384]))\n",
    "    h1 = tf.matmul(Z,w1)\n",
    "    re = tf.reshape(h1,[-1,4,4,1024])\n",
    "    re = tf.layers.batch_normalization(re)\n",
    "\n",
    "    conv_h1 = tf.layers.conv2d_transpose(re ,512, 5, 2, padding='same')\n",
    "    \n",
    "    conv_h1 = tf.nn.relu(conv_h1)\n",
    "\n",
    "    conv_h2 = tf.layers.conv2d_transpose(conv_h1 ,256, 4, 2, padding='same')\n",
    "    conv_h2 = tf.nn.relu(conv_h2)\n",
    "\n",
    "    conv_h3 = tf.layers.conv2d_transpose(conv_h2 ,128, 4, 2, padding='same')\n",
    "    conv_h3 = tf.nn.relu(conv_h3)\n",
    "\n",
    "    conv_h5 = tf.layers.conv2d_transpose(conv_h3 ,3, 4, 2, padding='same')\n",
    "    return conv_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_transpose_128/BiasAdd:0' shape=(?, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminaster(inputs):\n",
    "    W1 = tf.Variable(tf.random_normal([3,3,3,32],stddev=0.02))\n",
    "    H1 = tf.nn.conv2d(inputs,W1, strides=[1,2,2,1], padding=\"SAME\")\n",
    "    H1 = tf.layers.batch_normalization(H1)\n",
    "    H1 = tf.nn.relu(H1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([3,3,32,64],stddev=0.02))\n",
    "    H2 = tf.nn.conv2d(H1,W2, strides=[1,2,2,1], padding=\"SAME\")\n",
    "    H2 = tf.nn.relu(H2)\n",
    "\n",
    "    W3 = tf.Variable(tf.random_normal([3,3,64,256],stddev=0.02))\n",
    "    H3 = tf.nn.conv2d(H2,W3, strides=[1,2,2,1], padding=\"SAME\")\n",
    "    H3 = tf.nn.relu(H3)\n",
    "    \n",
    "    W4 = tf.Variable(tf.random_normal([3,3,256,1024],stddev=0.02))\n",
    "    H4 = tf.nn.conv2d(H3,W4, strides=[1,2,2,1], padding=\"SAME\")\n",
    "    H4 = tf.nn.relu(H4)\n",
    "    \n",
    "    out = tf.reshape(H4,[-1,16384])\n",
    "    out = tf.layers.dense(out,256)\n",
    "    out = tf.layers.dense(out,1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_44/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminaster(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generate(Z)\n",
    "D_real = discriminaster(X)\n",
    "D_gene = discriminaster(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real,labels=tf.ones_like(D_real)))\n",
    "\n",
    "loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene,labels=tf.zeros_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = loss_D_gene + loss_D_real\n",
    "loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene, labels=tf.ones_like(D_gene)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = tf.train.AdamOptimizer(0.001).minimize(loss_D)\n",
    "train_G = tf.train.AdamOptimizer(0.001).minimize(loss_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   D : 0.07073806\t G : 7.2089667\n",
      "1   D : 0.50758207\t G : 4.7999544\n",
      "2   D : 0.4613163\t G : 4.5590897\n",
      "3   D : 0.5115844\t G : 5.399264\n",
      "4   D : 0.3152466\t G : 6.12383\n",
      "5   D : 0.10904441\t G : 7.3741455\n",
      "6   D : 0.13261847\t G : 7.2677674\n",
      "7   D : 0.08520225\t G : 7.6240573\n",
      "8   D : 0.26991147\t G : 6.215007\n",
      "9   D : 0.18053775\t G : 6.558314\n",
      "10   D : 0.51203775\t G : 4.836068\n",
      "11   D : 0.13179043\t G : 6.8006134\n",
      "12   D : 0.21708366\t G : 6.186818\n",
      "13   D : 0.23863378\t G : 6.165909\n",
      "14   D : 0.49845076\t G : 4.97559\n",
      "15   D : 0.6637564\t G : 5.1771126\n",
      "16   D : 0.071461864\t G : 8.373516\n",
      "17   D : 0.14756085\t G : 6.819016\n",
      "18   D : 0.3144809\t G : 6.4568844\n",
      "19   D : 0.28568918\t G : 6.4791083\n",
      "20   D : 0.15415771\t G : 6.4629035\n",
      "21   D : 0.1226498\t G : 6.7484255\n",
      "22   D : 0.29426476\t G : 6.4842587\n",
      "23   D : 0.10502135\t G : 7.6078663\n",
      "24   D : 0.1682503\t G : 6.730981\n",
      "25   D : 0.0610506\t G : 7.910382\n",
      "26   D : 0.10695939\t G : 6.8418837\n",
      "27   D : 0.7690029\t G : 4.595644\n",
      "28   D : 0.2920626\t G : 5.738755\n",
      "29   D : 0.69480026\t G : 4.483655\n",
      "30   D : 0.38722\t G : 5.6828957\n",
      "31   D : 0.3331005\t G : 6.321685\n",
      "32   D : 1.1141089\t G : 3.762833\n",
      "33   D : 0.39804915\t G : 6.9289584\n",
      "34   D : 0.16408914\t G : 7.7644677\n",
      "35   D : 0.007015415\t G : 12.955221\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    noise = get_noise(1,100)\n",
    "    _, varsD=sess.run([train_D, loss_D], \n",
    "                  feed_dict={\n",
    "                      X:np.array(images),\n",
    "                      Z: noise})\n",
    "    _, varsG=sess.run([train_G, loss_G], \n",
    "                  feed_dict={\n",
    "                      X:np.array(images),\n",
    "                      Z: noise})\n",
    "    print(str(i)+\"   D : \"+str(varsD)+\"\\t G : \"+str(varsG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = get_noise(1,100)\n",
    "i = sess.run(G, feed_dict={Z:noise})\n",
    "windowUp(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = get_noise(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
